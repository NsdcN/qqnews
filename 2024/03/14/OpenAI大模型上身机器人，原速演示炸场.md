# OpenAI大模型上身机器人，原速演示炸场

编辑部 发自 凹非寺

量子位 | 公众号 QbitAI

OpenAI大模型加持的机器人，深夜来袭！

名曰**Figure 01** ，它能听会说，动作灵活。

能和人类描述眼前看到的一切：

我在桌子上看到了一个红色的苹果，沥水架上面还有几个盘子和一个杯子；然后你站在附近，手放在桌子上。

听到人类说“想吃东西”，就马上递过去苹果。

而且对于自己做的事有清楚认知，给苹果是因为这是桌上唯一能吃的东西。

还顺便把东西整理，能**同时搞定两种任务** 。

最关键的是，这些展示都**没有加速** ，机器人本来的动作就这么迅速。

（也没人在后面操纵）

这下网友坐不住了，立马@波士顿动力：

老伙计们，这家伙是真来劲儿了。咱得回实验室，让以前的机器人（波士顿动力）多跳点舞了。

![c8c8bf1c9f702a54e522091cbf0b5fb6.jpg](https://raw.githubusercontent.com/qqhsx/qqnews_image/main/2024/03/14/OpenAI大模型上身机器人，原速演示炸场/c8c8bf1c9f702a54e522091cbf0b5fb6.jpg)

也有网友看在OpenAI卷完大语言模型、文生视频之后，又狙击机器人后感慨道：

这是一场激烈的竞争；与OpenAl合作，苹果可能会超越特斯拉。

但硬件方面，擎天柱看起来更美观，Figure 01仍然需要一些“整容手术”。（doge）

![8e003b96432873dbab5d5940b0b2d4e3.jpg](https://raw.githubusercontent.com/qqhsx/qqnews_image/main/2024/03/14/OpenAI大模型上身机器人，原速演示炸场/8e003b96432873dbab5d5940b0b2d4e3.jpg)

接下来，我们继续来看下Figure 01的细节。

OpenAI视觉语言大模型加持

根据创始人的介绍，Figure 01通过端到端神经网络，可以和人类自如对话。

基于OpenAI提供的视觉理解和语言理解能力，它能完成快速、简单、灵巧的动作。

模型只说是一个视觉语言大模型，是否为GPT-4V不得而知。

![6afb4d26a219a96145f4fe692c67e2c7.jpg](https://raw.githubusercontent.com/qqhsx/qqnews_image/main/2024/03/14/OpenAI大模型上身机器人，原速演示炸场/6afb4d26a219a96145f4fe692c67e2c7.jpg)

它还能规划动作、有短期记忆能力、用语言解释它的推理过程。

![95a7076a741295d816589f500a69e24b.jpg](https://raw.githubusercontent.com/qqhsx/qqnews_image/main/2024/03/14/OpenAI大模型上身机器人，原速演示炸场/95a7076a741295d816589f500a69e24b.jpg)

比如对话里说“你能把它们放在那里吗？”

“它们”、“那里”这种模糊表述的理解，就体现了机器人的短期记忆能力。

它使用了OpenAI训练的**视觉语言模型** ，机器人摄像头会以10Hz拍下画面，然后神经网络将以200Hz输出**24自由度**
动作（手腕+手指关节角度）。

具体分工上，机器人的策略也很像人类。

复杂动作交给AI大模型，预训练模型会对图像和文本进行常识推理，给出动作计划；

简单动作如抓起塑料袋（抓哪里都可以），机器人基于已学习的视觉-动作执行策略，可以做出一些“下意识”的快速反应行动。

同时全身控制器会负责保持机身平衡、运动稳定。

机器人的语音能力则基于一个文本-语音大模型微调而来。

![9aafa7b38945b5c102317b967b5ba5ce.jpg](https://raw.githubusercontent.com/qqhsx/qqnews_image/main/2024/03/14/OpenAI大模型上身机器人，原速演示炸场/9aafa7b38945b5c102317b967b5ba5ce.jpg)

除了最先进的AI模型，Figure 01背后公司——Figure的创始人兼CEO还在推文中提到，Figure方面整合了机器人的所有关键组成。

包括电机、中间件操作系统、传感器、机械结构等，均由Figure工程师设计。

据了解，这家机器人初创公司在2周前才正式宣布和OpenAI的合作，但才13天后就带来如此重磅成果。不少人都开始期待后续合作了。

![d4a497701d25636bd375f0c6bea9393d.jpg](https://raw.githubusercontent.com/qqhsx/qqnews_image/main/2024/03/14/OpenAI大模型上身机器人，原速演示炸场/d4a497701d25636bd375f0c6bea9393d.jpg)

由此，具身智能领域又有一颗新星走到了聚光灯下。

“将人形机器人带进生活”

说到Figure，这家公司创立于2022年，正如前文所言，再次引爆外界关注，就在十几天前——

官宣在新一轮融资中筹集6.75亿美元，估值冲到26亿美元，投资方几乎要集齐半个硅谷，包括微软、OpenAI、英伟达和亚马逊创始人贝佐斯等等。

更重要的是，OpenAI同时公开了与Figure更进一步合作的计划：将多模态大模型的能力扩展到机器人的感知、推理和交互上，“开发能够取代人类进行体力劳动的人形机器人”。

用现在最热的科技词汇来说，就是要一起搞**具身智能** 。

![a42007dd5205d902c44ff8c35c021466.jpg](https://raw.githubusercontent.com/qqhsx/qqnews_image/main/2024/03/14/OpenAI大模型上身机器人，原速演示炸场/a42007dd5205d902c44ff8c35c021466.jpg)

彼时，Figure 01的最新进展是酱婶的：

通过观看人类的示范视频，仅需10小时端到端训练，Figure 01就能学会用胶囊咖啡机泡咖啡。

Figure与OpenAI的合作一公开，网友们就已经对未来的突破充满了期待。

![cfd668551e568fe65747c35943f12924.jpg](https://raw.githubusercontent.com/qqhsx/qqnews_image/main/2024/03/14/OpenAI大模型上身机器人，原速演示炸场/cfd668551e568fe65747c35943f12924.jpg)

毕竟Brett Adcock，可是把“唯一的重点是以30年的视角建立Figure，以积极影响人类的未来”这样的话都写在个人主页上了。

但可能没人能想得到，仅仅两周左右的时间，新进展就来了。

如此之快，如此之远。并且还能持续泛化、扩展规模。

![9f3a5497d0cb69568488ad70418cd9f1.jpg](https://raw.githubusercontent.com/qqhsx/qqnews_image/main/2024/03/14/OpenAI大模型上身机器人，原速演示炸场/9f3a5497d0cb69568488ad70418cd9f1.jpg)

值得一提的是，与炸场demo同时发布的，还有Figure的招聘信息：

我们正在将人形机器人带进生活。加入我们。

![cd622a3c601906c27341d39dff984226.jpg](https://raw.githubusercontent.com/qqhsx/qqnews_image/main/2024/03/14/OpenAI大模型上身机器人，原速演示炸场/cd622a3c601906c27341d39dff984226.jpg)

参考链接：

[1]https://twitter.com/figure_robot/status/1767913661253984474?s=46&t=HBob6gxh8cOfZTIbieKeSA

[2]https://twitter.com/adcock_brett/status/1767913955295744449

[3]https://twitter.com/coreylynch/status/1767927194163331345

— 完 —

